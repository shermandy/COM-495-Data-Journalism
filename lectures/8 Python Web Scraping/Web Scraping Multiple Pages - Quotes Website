from bs4 import BeautifulSoup
import requests
from time import sleep
from random import randint
import csv

quotes = []

pages = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']

for page in pages:

	link = requests.get('http://quotes.toscrape.com/page/' + page)

	sleep(randint(1,5))

	soup = BeautifulSoup(link.text, 'lxml')

	results = soup.find_all('div', attrs={'class':'quote'})

	for result in results:
		quote = result.find('span', attrs={'class':'text'}).text.encode('utf-8')
		author = result.find('small', attrs={'class':'author'}).text.encode('utf-8')
		quotes.append([quote, author])

with open('output.csv', 'a') as csv_file:
	csv_output = csv.writer(csv_file)
	csv_output.writerows(quotes)
